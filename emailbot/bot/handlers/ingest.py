"""Handlers for ingest flow powered by aiogram."""

from __future__ import annotations

import io
import re
from typing import Iterable

from aiogram import F, Router, types
from aiogram.exceptions import TelegramBadRequest
from aiogram.types import CallbackQuery
from aiogram.utils.keyboard import InlineKeyboardBuilder
from aiogram.utils.markdown import hcode

from emailbot.messaging_utils import is_blocked, is_suppressed
from emailbot.pipelines.ingest import ingest_emails
from emailbot.pipelines.ingest_url import ingest_url
from emailbot.settings import resolve_label
from emailbot.utils.file_email_extractor import ExtractError, extract_emails_from_bytes
from emailbot.ui.messages import format_parse_summary

router = Router()
URL_RE = re.compile(r"""(?ix)\b((?:https?://)?(?:www\.)?[^\s<>()]+?\.[^\s<>()]{2,}[^\s<>()]*)(?=$|[\s,;:!?)}\]])""")
REJECT_LABELS = {
    "no_at_sign": "Ð½ÐµÑ‚ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð° @",
    "empty_local_or_domain": "Ð¿ÑƒÑÑ‚Ð°Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒ/Ð´Ð¾Ð¼ÐµÐ½",
    "local_not_ascii": "Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ Ð½Ðµ ASCII",
    "local_edge_dot": "Ñ‚Ð¾Ñ‡ÐºÐ° Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ/ÐºÐ¾Ð½Ñ†Ðµ Ð»Ð¾ÐºÐ°Ð»Ð¸",
    "local_consecutive_dots": "Ð´Ð²Ðµ Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð¿Ð¾Ð´Ñ€ÑÐ´ Ð² Ð»Ð¾ÐºÐ°Ð»Ð¸",
    "local_bad_chars": "Ð½ÐµÐ´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð² Ð»Ð¾ÐºÐ°Ð»Ð¸",
    "domain_bad_shape": "Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð´Ð¾Ð¼ÐµÐ½",
    "domain_idna_fail": "Ð¾ÑˆÐ¸Ð±ÐºÐ° IDNA-ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð´Ð¾Ð¼ÐµÐ½Ð°",
    "domain_too_long": "ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹ Ð´Ð¾Ð¼ÐµÐ½",
    "domain_label_size": "Ð´Ð»Ð¸Ð½Ð° Ð»ÐµÐ¹Ð±Ð»Ð° Ð´Ð¾Ð¼ÐµÐ½Ð° Ð½ÐµÐ²ÐµÑ€Ð½Ð°",
    "domain_label_dash": "Ð»ÐµÐ¹Ð±Ð» Ð´Ð¾Ð¼ÐµÐ½Ð° Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ/Ð·Ð°ÐºÐ°Ð½Ñ‡Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð´ÐµÑ„Ð¸ÑÐ¾Ð¼",
    "missing_dep_openpyxl": "Ð½ÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ openpyxl Ð´Ð»Ñ .xlsx",
    "missing_dep_python_docx": "Ð½ÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ python-docx Ð´Ð»Ñ .docx",
    "missing_dep_pdfminer": "Ð½ÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ pdfminer.six Ð´Ð»Ñ .pdf",
    "unknown": "Ð¸Ð½Ð°Ñ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°",
}


_LAST_URLS: dict[int, str] = {}


def _format_rejects(rejects: dict[str, int], mapping: dict[str, str] | None = None) -> str:
    if not rejects:
        return ""
    mapping = mapping or REJECT_LABELS
    lines = ["\nÐŸÑ€Ð¸Ñ‡Ð¸Ð½Ñ‹ Ð¾Ñ‚Ð±Ñ€Ð°ÐºÐ¾Ð²ÐºÐ¸:"]
    for code, count in rejects.items():
        lines.append(f" â€¢ {mapping.get(code, code)} â€” {count}")
    return "\n".join(lines)


def _filter_stoplists(addresses: Iterable[str]) -> list[str]:
    return [email for email in addresses if not (is_blocked(email) or is_suppressed(email))]


@router.message(F.text & F.text.startswith("/ingest"))
async def handle_ingest(msg: types.Message) -> None:
    """Process `/ingest` command with newline separated addresses."""

    lines = [line for line in msg.text.splitlines()[1:] if line.strip()]
    ok, bad, stats = ingest_emails(lines)
    text = (
        f"Ð’ÑÐµÐ³Ð¾ ÑÑ‚Ñ€Ð¾Ðº: {stats['total_in']}\n"
        f"Ð“Ð¾Ð´Ð½Ñ‹Ñ… Ð°Ð´Ñ€ÐµÑÐ¾Ð²: {stats['ok']}\n"
        f"ÐžÑ‚Ð±Ñ€Ð¾ÑˆÐµÐ½Ð¾: {stats['bad']}"
    )
    rejects = stats.get("rejects") or {}
    text += _format_rejects(rejects)
    if ok:
        text += "\n\nÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:\n" + "\n".join(hcode(x) for x in ok[:5])
    if bad:
        text += "\n\nÐžÑ‚Ð±Ñ€Ð¾ÑˆÐµÐ½Ð½Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸:\n" + "\n".join(hcode(x) for x in bad[:5])
    await msg.answer(text)


@router.message(F.text.regexp(URL_RE))
async def handle_url(msg: types.Message) -> None:
    if not msg.text:
        return
    if msg.text.startswith("/ingest"):
        return
    match = URL_RE.search(msg.text)
    if not match:
        return
    url = match.group(1)
    url = url.rstrip(".,;:!?)]}")
    if not url.lower().startswith(("http://", "https://")):
        url = f"https://{url}"
    user_id = msg.from_user.id if msg.from_user else None
    if user_id is not None:
        _LAST_URLS[user_id] = url
    builder = InlineKeyboardBuilder()
    builder.button(text="ðŸ”Ž ÐŸÐ°Ñ€ÑÐ¸Ñ‚ÑŒ ÑÑ‚Ñƒ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñƒ", callback_data="parse_url:single")
    builder.button(
        text="ðŸ•·ï¸ Ð¡ÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ°Ð¹Ñ‚ (Ð´Ð¾ 50 ÑÑ‚Ñ€.)",
        callback_data="parse_url:deep",
    )
    builder.adjust(1)
    await msg.answer(
        f"ÐÐ°ÑˆÐ»Ð° ÑÑÑ‹Ð»ÐºÑƒ:\n{hcode(url)}\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÐ¶Ð¸Ð¼:",
        reply_markup=builder.as_markup(),
    )


async def _process_url_callback(callback: CallbackQuery, *, deep: bool) -> None:
    user_id = callback.from_user.id if callback.from_user else None
    if user_id is None:
        await callback.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ", show_alert=True)
        return
    url = _LAST_URLS.get(user_id)
    if not url:
        await callback.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ", show_alert=True)
        return
    status_text = (
        f"ðŸ•·ï¸ Ð¡ÐºÐ°Ð½Ð¸Ñ€ÑƒÑŽ ÑÐ°Ð¹Ñ‚ (Ð´Ð¾ 50 ÑÑ‚Ñ€.):\n{hcode(url)}"
        if deep
        else f"ðŸ”Ž ÐŸÐ°Ñ€ÑÑŽ Ð¾Ð´Ð½Ñƒ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñƒ:\n{hcode(url)}"
    )
    try:
        await callback.message.edit_text(status_text)
    except TelegramBadRequest:
        await callback.message.answer(status_text)
    try:
        ok, stats = await ingest_url(url, deep=deep)
    except Exception as exc:  # pragma: no cover - network errors are variable
        await callback.message.answer(
            f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ {hcode(url)}: {exc}"
        )
        await callback.answer()
        return
    filtered = list(dict.fromkeys(_filter_stoplists(ok)))
    summary = format_parse_summary(
        {
            "total_found": stats.get("total_in", 0),
            "to_send": len(filtered),
            "suspicious": 0,
            "cooldown_180d": 0,
            "foreign_domain": 0,
            "pages_skipped": 0,
            "footnote_dupes_removed": 0,
            "blocked": stats.get("blocked", 0),
            "blocked_after_parse": stats.get("blocked", 0),
        },
        examples=filtered[:5],
    )
    if filtered:
        summary += "\nÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:\n" + "\n".join(hcode(addr) for addr in filtered[:5])
    pages = stats.get("pages", 0)
    if deep and pages:
        summary += f"\n\nðŸŒ ÐŸÑ€Ð¾ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†: {pages}"
    await callback.message.answer(summary)
    await callback.answer()


@router.callback_query(F.data == "parse_url:single")
async def parse_single(callback: CallbackQuery) -> None:
    await _process_url_callback(callback, deep=False)


@router.callback_query(F.data == "parse_url:deep")
async def parse_deep(callback: CallbackQuery) -> None:
    await _process_url_callback(callback, deep=True)


@router.message(F.document)
async def handle_document(msg: types.Message) -> None:
    doc = msg.document
    ack = await msg.reply(f"ÐŸÑ€Ð¸Ð½ÑÐ»Ð° Ñ„Ð°Ð¹Ð»: {doc.file_name}. ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽâ€¦")
    buffer = io.BytesIO()
    await msg.bot.download(doc, destination=buffer)
    data = buffer.getvalue()
    try:
        ok, rejects, warn = extract_emails_from_bytes(data, doc.file_name or "file")
    except ExtractError as exc:
        await ack.edit_text(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»: {exc}")
        return
    except Exception:  # pragma: no cover - unexpected decoding errors
        await ack.edit_text("ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°Ð·Ð±Ð¾Ñ€Ðµ Ñ„Ð°Ð¹Ð»Ð°.")
        return

    ok = list(dict.fromkeys(_filter_stoplists(ok)))
    text = f"Ð“Ð¾Ñ‚Ð¾Ð²Ð¾.\nÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð°Ð´Ñ€ÐµÑÐ¾Ð²: {len(ok)}"
    text += _format_rejects(rejects)
    if warn:
        text += f"\n\nâš ï¸ {warn}"
    if ok:
        text += "\n\nÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:\n" + "\n".join(hcode(x) for x in ok[:5])
    await ack.edit_text(text)


@router.callback_query(F.data.startswith("set_group:"))
async def set_group(callback: CallbackQuery) -> None:
    """Handle group selection from inline keyboard."""

    label = callback.data.split("set_group:", 1)[1]
    slug = resolve_label(label)
    await callback.message.answer(f"Ð’Ñ‹ Ð²Ñ‹Ð±Ñ€Ð°Ð»Ð¸: {label} ({slug})")
    await callback.answer()
