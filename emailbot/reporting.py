"""Utilities for composing user-facing reports."""

from __future__ import annotations

import json
import logging
from datetime import datetime
from typing import Iterable, List, Optional

from emailbot.suppress_list import is_blocked


def _now_ts() -> str:
    return datetime.utcnow().isoformat(timespec="milliseconds") + "Z"


_DIGEST_LOGGER = logging.getLogger("emailbot.digest")


def log_extract_digest(stats: dict) -> None:
    """Log a one-line JSON digest for extraction statistics."""

    data = {
        "ts": _now_ts(),
        "level": "INFO",
        "component": "extract",
        "footnote_singletons_repaired": stats.get("footnote_singletons_repaired", 0),
        "footnote_guard_skips": stats.get("footnote_guard_skips", 0),
        "footnote_ambiguous_kept": stats.get("footnote_ambiguous_kept", 0),
        "left_guard_skips": stats.get("left_guard_skips", 0),
        "prefix_expanded": stats.get("prefix_expanded", 0),
        "phone_prefix_stripped": stats.get("phone_prefix_stripped", 0),
    }
    data.update(stats)
    _DIGEST_LOGGER.info(json.dumps(data, ensure_ascii=False))


def log_mass_filter_digest(ctx: dict) -> None:
    """Log a one-line JSON digest for mass-mail filter statistics."""

    data = {"ts": _now_ts(), "level": "INFO", "component": "mass_filter"}
    data.update(ctx)
    _DIGEST_LOGGER.info(json.dumps(data, ensure_ascii=False))


def render_summary(stats: dict) -> str:
    """Render a short textual summary for extraction statistics."""

    lines: List[str] = []

    total_found = stats.get("total_found")
    if total_found is not None:
        lines.append(f"ğŸ“Š ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ°Ğ´Ñ€ĞµÑĞ¾Ğ²: {total_found}")

    to_send = stats.get("unique_after_cleanup")
    if to_send is None:
        to_send = stats.get("total_ready", 0)
    lines.append(f"ğŸ“¦ Ğš Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞµ: {to_send}")

    suspicious = stats.get("suspicious_numeric_localpart")
    if suspicious:
        lines.append(f"ğŸŸ¡ ĞŸĞ¾Ğ´Ğ¾Ğ·Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ: {suspicious}")

    blocked_total = stats.get("blocked_total", 0)
    lines.append(f"ğŸš« Ğ˜Ğ· Ğ±Ğ»Ğ¾Ğº-Ğ»Ğ¸ÑÑ‚Ğ°: {blocked_total}")

    missed_pages = stats.get("pdf_pages_failed")
    if missed_pages:
        lines.append(f"ğŸ“„ ĞĞµ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ñ‹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ PDF: {missed_pages}")

    invalid_tld = stats.get("invalid_tld")
    if invalid_tld:
        lines.append(f"â— ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ Ğ´Ğ¾Ğ¼ĞµĞ½Ñ‹: {invalid_tld}")

    return "\n".join(lines)


def build_mass_report_text(
    sent_ok: Iterable[str],
    skipped_recent: Iterable[str],
    blocked_foreign: Optional[Iterable[str]] = None,
    blocked_invalid: Optional[Iterable[str]] = None,
    duplicates_24h: Optional[Iterable[str]] = None,
) -> str:
    """Build summary text for mass mailing.

    The function returns only aggregate counts without revealing individual
    eâ€‘mail addresses. ``blocked_foreign`` and ``blocked_invalid`` are accepted for
    backward compatibility and counted in the summary.
    """

    sent_cnt = len(list(sent_ok))
    skipped_cnt = len(list(skipped_recent))
    blocked_cnt = len(list(blocked_invalid or []))
    foreign_cnt = len(list(blocked_foreign or []))
    dup_cnt = len(list(duplicates_24h or []))
    total = sent_cnt + skipped_cnt + blocked_cnt + foreign_cnt + dup_cnt

    lines = [
        "âœ‰ï¸ Ğ Ğ°ÑÑÑ‹Ğ»ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°.",
        f"ğŸ“¦ Ğ’ Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ¸ Ğ±Ñ‹Ğ»Ğ¾: {total}",
        f"âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: {sent_cnt}",
        f"â³ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ñ‹ (Ğ¿Ğ¾ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ñƒ Â«180 Ğ´Ğ½ĞµĞ¹Â»): {skipped_cnt}",
        f"ğŸš« Ğ’ Ğ±Ğ»Ğ¾Ğº-Ğ»Ğ¸ÑÑ‚Ğµ/Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹: {blocked_cnt}",
        f"ğŸŒ Ğ˜Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ğµ (Ğ¾Ñ‚Ğ»Ğ¾Ğ¶ĞµĞ½Ñ‹): {foreign_cnt}",
    ]
    if dup_cnt:
        lines.append(f"ğŸ” Ğ”ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ Ğ·Ğ° 24 Ñ‡: {dup_cnt}")
    return "\n".join(lines)


def count_blocked(emails: Iterable[str]) -> int:
    """Return how many addresses are present in the block list."""

    return sum(1 for email in emails if is_blocked(email))
