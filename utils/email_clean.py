from __future__ import annotations

import logging
import os
import re
import unicodedata
from typing import Iterable

try:
    import idna  # type: ignore
except Exception:  # fallback
    idna = None  # type: ignore

logger = logging.getLogger(__name__)

CONFUSABLES_NORMALIZE = os.getenv("CONFUSABLES_NORMALIZE", "1") == "1"
OBFUSCATION_ENABLE = os.getenv("OBFUSCATION_ENABLE", "1") == "1"

# –ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ –≥–æ–º–æ–≥–ª–∏—Ñ—ã ‚Üí –ª–∞—Ç–∏–Ω–∏—Ü–∞ (–∫—Ä–∏—Ç–∏—á–Ω–æ: ¬´—Ö¬ª‚Üí'x')
CYR_TO_LAT = {
    "–∞": "a",
    "–µ": "e",
    "–æ": "o",
    "—Ä": "p",
    "—Å": "s",
    "—É": "y",
    "–∫": "k",
    "—Ö": "x",
    "–≤": "v",
    "–º": "m",
    "—Ç": "t",
    "–Ω": "h",
    "–ê": "A",
    "–í": "B",
    "–ï": "E",
    "–ö": "K",
    "–ú": "M",
    "–ù": "H",
    "–û": "O",
    "–†": "P",
    "–°": "C",
    "–¢": "T",
    "–•": "X",
}

_INVISIBLES_RE = re.compile(r"[\u200B-\u200F\u202A-\u202E\u2066-\u2069\uFEFF]")

EMAIL_RE = re.compile(r"(?ix)\b" r"[a-z0-9._%+\-]+@(?:[a-z0-9\-]+\.)+[a-z0-9\-]{2,}" r"\b")

# –í–ê–ñ–ù–û: (?<!@) ‚Äî —á—Ç–æ–±—ã –¥–æ–º–µ–Ω–Ω–∞—è —á–∞—Å—Ç—å e-mail –Ω–µ —Å—á–∏—Ç–∞–ª–∞—Å—å —Å—Å—ã–ª–∫–æ–π
SAFE_URL_RE = re.compile(
    r"(?ix)(?<!@)\b((?:https?://)?(?:www\.)?[^\s<>()]+?\.[^\s<>()]{2,}[^\s<>()]*)(?=$|[\s,;:!?)}\]])"
)

# ---------------------------------------------------------------------------
#  –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –û–†–ò–ì–ò–ù–ê–õ–ê (–Ω—É–∂–Ω–∞ –¥–ª—è emailbot/handlers/preview.py)
#  –û–±—ä—è–≤–ª—è–µ–º –†–ê–ù–û (–≤—ã—à–µ –ø–æ —Ñ–∞–π–ª—É), —á—Ç–æ–±—ã —Ç–æ—á–Ω–æ —É—Å–ø–µ—Ç—å –∫ –º–æ–º–µ–Ω—Ç—É –∏–º–ø–æ—Ä—Ç–∞.
# ---------------------------------------------------------------------------
def dedupe_keep_original(emails, return_map: bool = False):
    """
    –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∫–∞–Ω–æ–Ω—É, –Ω–æ –≤–µ—Ä–Ω—É—Ç—å –ü–ï–†–í–´–ô –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω—ã–π –û–†–ò–ì–ò–ù–ê–õ —Å—Ç—Ä–æ–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      - —Å–ø–∏—Å–æ–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤ (–≤ –ø–æ—Ä—è–¥–∫–µ –ø–µ—Ä–≤–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è) –±–µ–∑ –¥—É–±–ª–µ–π –ø–æ –∫–∞–Ω–æ–Ω—É;
      - –ø—Ä–∏ return_map=True ‚Üí (result, canonical->set(originals)).
    """

    if not emails:
        return ([], {}) if return_map else []
    seen = set()
    mapping = {}
    result = []
    for raw in emails:
        e = (raw or "").strip()
        if not e:
            continue
        try:
            # canonical_email –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –Ω–∏–∂–µ –≤ —ç—Ç–æ–º –º–æ–¥—É–ª–µ; –µ—Å–ª–∏ –ø–æ—Ä—è–¥–æ–∫ –∏–º–ø–æ—Ä—Ç–∞
            # –µ—â—ë –Ω–µ –¥–æ—à—ë–ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –º—è–≥–∫–∏–π —Ñ–æ–ª–±—ç–∫ –Ω–∞ lowercase.
            canon = canonical_email(e)  # type: ignore[name-defined]
        except Exception:
            canon = e.lower()
        mapping.setdefault(canon, set()).add(e)
        if canon in seen:
            continue
        seen.add(canon)
        result.append(e)
    if return_map:
        return result, mapping
    return result

# ¬´–ú—É—Å–æ—Ä¬ª –Ω–∞ –∫—Ä–∞—è—Ö —Ç–æ–∫–µ–Ω–∞: –ø—Ä–æ–±–µ–ª—ã, NBSP/soft hyphen, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è, –∫–∞–≤—ã—á–∫–∏, —Ç–∏—Ä–µ, –º–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–æ–≤
_LEADING_JUNK_RE = re.compile(
    r'^[\s\u00A0\u00AD\.\-‚Äì‚Äî¬∑‚Ä¢_*~=:;|/\\<>\(\)\[\]\{\}"\'`¬´¬ª‚Äû‚Äú‚Äù‚Äö‚Äò‚Äô]+'
)
_TRAILING_JUNK_RE = re.compile(
    r'[\s\u00A0\u00AD\.\-‚Äì‚Äî¬∑‚Ä¢_*~=:;|/\\<>\(\)\[\]\{\}"\'`¬´¬ª‚Äû‚Äú‚Äù‚Äö‚Äò‚Äô]+$'
)


def drop_leading_char_twins(s: str) -> str:
    """
    Legacy helper: —É–±—Ä–∞—Ç—å ¬´–∑–¥–≤–æ–µ–Ω–Ω—ã–µ¬ª/–ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –≤–µ–¥—É—â–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –æ–±—â—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    –≤ –Ω–∞—á–∞–ª–µ —Ç–æ–∫–µ–Ω–∞ (–±—É–ª–ª–µ—Ç—ã, —Ç–∏—Ä–µ, —Ç–æ—á–∫–∏, –∫–∞–≤—ã—á–∫–∏ –∏ —Ç.–ø.).
    """

    if not s:
        return s
    return _LEADING_JUNK_RE.sub("", s)


def drop_trailing_char_twins(s: str) -> str:
    """
    –ü–∞—Ä–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —É–±—Ä–∞—Ç—å —Ö–≤–æ—Å—Ç–æ–≤–æ–π ¬´–º—É—Å–æ—Ä¬ª/–ø–æ–≤—Ç–æ—Ä—ã –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ü–µ —Ç–æ–∫–µ–Ω–∞.
    –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–∞ —Å–ª—É—á–∞–π —Å—Ç–∞—Ä—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ.
    """

    if not s:
        return s
    return _TRAILING_JUNK_RE.sub("", s)


def _normalize_confusables(text: str) -> str:
    if not text or not CONFUSABLES_NORMALIZE:
        return text
    t = unicodedata.normalize("NFC", text)
    return "".join(CYR_TO_LAT.get(ch, ch) for ch in t)


def strip_invisibles(text: str) -> str:
    return _INVISIBLES_RE.sub("", text or "")


def _idna_domain(domain: str) -> str:
    d = domain.strip().rstrip(".").lower()
    if not d or idna is None:
        return d or domain
    try:
        return idna.encode(d, uts46=True).decode("ascii")
    except Exception:
        return d


def preclean_for_email_extraction(text: str) -> str:
    t = strip_invisibles(text or "")
    t = _normalize_confusables(t)
    # —É–±—Ä–∞—Ç—å NBSP –∏ –º—è–≥–∫–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã, –≤—ã—Ä–æ–≤–Ω—è—Ç—å –ø—Ä–æ–±–µ–ª—ã
    t = t.replace("\u00A0", " ").replace("\u00AD", "")
    t = t.replace("\r", "\n")
    t = re.sub(r"[ \t]+", " ", t)
    return t.strip()


def _deobfuscate_chunks(chunks: Iterable[str]) -> Iterable[str]:
    if not OBFUSCATION_ENABLE:
        yield from chunks
        return
    subs = [
        (re.compile(r"(?i)\s*(?:\[at\]|\(at\)|\{at\}| at | —Å–æ–±–∞–∫–∞ )\s*"), "@"),
        (re.compile(r"(?i)\s*(?:\[dot\]|\(dot\)|\{dot\}| dot | —Ç–æ—á–∫–∞ )\s*"), "."),
    ]
    for s in chunks:
        t = s
        for rx, rep in subs:
            t = rx.sub(rep, t)
        yield t


def preclean_obfuscations(text: str) -> str:
    """Return ``text`` normalised for matching while undoing simple obfuscations."""

    cleaned = preclean_for_email_extraction(text)
    if not cleaned:
        return ""
    return "".join(_deobfuscate_chunks([cleaned]))


def parse_emails_unified(text: str, return_meta: bool = False):
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–≥–æ–º–æ–≥–ª–∏—Ñ—ã/–Ω–µ–≤–∏–¥–∏–º—ã–µ) ‚Üí –¥–µ–æ–±—Ñ—É—Å–∫–∞—Ü–∏—è ‚Üí –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ e-mail ‚Üí IDNA –¥–ª—è –¥–æ–º–µ–Ω–∞.
    """

    src = preclean_for_email_extraction(text)
    raw_chunks = re.split(r"[,\s;\n]+", src)
    chunks = list(_deobfuscate_chunks(raw_chunks))

    found = set()
    for tok in chunks:
        if not tok:
            continue
        m = EMAIL_RE.search(tok)
        if m:
            local, dom = m.group(0).split("@", 1)
            found.add(f"{local.lower()}@{_idna_domain(dom)}")
            continue
        # –ø–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç–∞—â–∏—Ç—å –∏–∑ —Ç–æ–∫–µ–Ω–∞ –±–µ–∑ –ª–∏—à–Ω–∏—Ö –æ–±—Ä–∞–º–ª–µ–Ω–∏–π
        # –º—è–≥–∫–∞—è –ø–æ–¥—á–∏—Å—Ç–∫–∞ –∫—Ä–∞—ë–≤ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å–æ —Å—Ç–∞—Ä—ã–º –ø–∞–π–ø–ª–∞–π–Ω–æ–º)
        core = drop_trailing_char_twins(drop_leading_char_twins(tok))
        for m in EMAIL_RE.finditer(core):
            local, dom = m.group(0).split("@", 1)
            found.add(f"{local.lower()}@{_idna_domain(dom)}")

    res = sorted(found)
    if return_meta:
        return res, {"source": text, "normalized": src, "tokens": chunks, "emails": res}
    return res


def contains_url_but_not_email(text: str) -> bool:
    cleaned = preclean_for_email_extraction(text or "")
    if EMAIL_RE.search(cleaned):
        return False
    return bool(SAFE_URL_RE.search(cleaned))


# ---------------------------------------------------------------------------
#  –ü—Ä–æ–≤–∞–π–¥–µ—Ä-aware –∫–∞–Ω–æ–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∞–¥—Ä–µ—Å–æ–≤
# ---------------------------------------------------------------------------

_PLUS_TAG_PROVIDERS = {
    "gmail.com",
    "googlemail.com",
    "yandex.ru",
    "yandex.com",
    "yandex.ua",
    "yandex.by",
    "yandex.kz",
    "yandex.com.tr",
    "ya.ru",
    "outlook.com",
    "hotmail.com",
    "live.com",
}

_IGNORE_DOTS_PROVIDERS = {
    # Gmail/Googlemail –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç —Ç–æ—á–∫–∏ –≤ local-part
    "gmail.com",
    "googlemail.com",
    # –Ø–Ω–¥–µ–∫—Å/ya.ru —Ç–æ–∂–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ç–æ—á–∫–∏
    "yandex.ru",
    "yandex.com",
    "yandex.ua",
    "yandex.by",
    "yandex.kz",
    "yandex.com.tr",
    "ya.ru",
}

_DOMAIN_ALIASES = {
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–Ω–æ–º—É –∫–∞–Ω–æ–Ω—É, —á—Ç–æ–±—ã –Ω–µ –ø–ª–æ–¥–∏—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã
    "googlemail.com": "gmail.com",
}


def _canonical_domain(dom: str) -> str:
    d = _idna_domain(dom.lower().strip())
    return _DOMAIN_ALIASES.get(d, d)


def _strip_plus_tag(local: str) -> str:
    # –≤—Å—ë, —á—Ç–æ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ '+', —Ä–µ–∂–µ–º (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ –¥–ª—è –º–Ω–æ–≥–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤)
    i = local.find("+")
    return local if i < 0 else local[:i]


def _canonical_local(local: str, domain: str) -> str:
    l = local.lower()
    d = domain.lower()
    if d in _PLUS_TAG_PROVIDERS:
        l = _strip_plus_tag(l)
    if d in _IGNORE_DOTS_PROVIDERS:
        l = l.replace(".", "")
    return l


def canonical_email(addr: str) -> str:
    """
    –ö–∞–Ω–æ–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è –∞–¥—Ä–µ—Å–∞: lowercase, IDNA –¥–ª—è –¥–æ–º–µ–Ω–∞, –ø—Ä–æ–≤–∞–π–¥–µ—Ä-—Å–ø–µ—Ü. –ø—Ä–∞–≤–∏–ª–∞.
    –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –≤—Ö–æ–¥ —É–∂–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏ –≤–∞–ª–∏–¥–µ–Ω.
    """

    local, dom = addr.split("@", 1)
    dom_c = _canonical_domain(dom)
    loc_c = _canonical_local(local, dom_c)
    return f"{loc_c}@{dom_c}"


def dedupe_with_variants(emails, return_map: bool = False):
    """
    –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å —É—á—ë—Ç–æ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä-–≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:
    - gmail/googlemail, yandex/ya: –∏–≥–Ω–æ—Ä —Ç–æ—á–µ–∫ –≤ local, —Ä–µ–∂–µ–º +tag
    - IDNA –∏ lowercase –¥–ª—è –¥–æ–º–µ–Ω–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      - —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ (–≤ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º –≤–∏–¥–µ);
      - –ø—Ä–∏ return_map=True –∫–æ—Ä—Ç–µ–∂ (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ, mapping), –≥–¥–µ
        mapping[canonical] = {–≤–∞—Ä–∏–∞–Ω—Ç—ã_–∫–∞–∫_–≤–≤–æ–¥–∏–ª–∏—Å—å}.
    """

    if not emails:
        return ([], {}) if return_map else []
    mapping: dict[str, set[str]] = {}
    for raw in emails:
        e = (raw or "").strip().lower()
        if not e or "@" not in e:
            continue
        try:
            local, dom = e.split("@", 1)
        except ValueError:
            continue
        dom_c = _canonical_domain(dom)
        loc_c = _canonical_local(local, dom_c)
        canon = f"{loc_c}@{dom_c}"
        mapping.setdefault(canon, set()).add(e)
    uniques = sorted(mapping.keys())
    if return_map:
        return uniques, mapping
    return uniques

# ---------------------------------------------------------------------------
#  –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º (legacy API)
# ---------------------------------------------------------------------------

def finalize_email(addr: str) -> str:
    """
    Backward-compatible stub.
    –°—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ pipelines/extract_emails.py –∏ messaging.py –≤—ã–∑—ã–≤–∞–ª–∏ finalize_email
    –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–¥—Ä–µ—Å–æ–≤. –¢–µ–ø–µ—Ä—å —ç—Ç–æ –¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç—Å—è canonical_email().
    """
    try:
        return canonical_email(addr)
    except Exception as e:
        logger.warning("finalize_email fallback for %r: %s", addr, e)
        return (addr or "").strip().lower()


def normalize_email(addr: str) -> str:
    """
    –†–∞–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –¥–ª—è ¬´–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏¬ª, —Ç–µ–ø–µ—Ä—å –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç canonical_email().
    –û—Å—Ç–∞–≤–ª–µ–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ –∏–º–ø–æ—Ä—Ç–∞–º–∏.
    """

    try:
        return canonical_email(addr)
    except Exception as e:
        logger.warning("normalize_email fallback for %r: %s", addr, e)
        return (addr or "").strip().lower()


def repair_email(addr: str) -> str:
    """
    Legacy: –ø–æ–ø—ã—Ç–∫–∞ ¬´–ø–æ–¥–ª–µ—á–∏—Ç—å¬ª –∞–¥—Ä–µ—Å (–æ–±—Ä–µ–∑–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–µ—Å—Ç–∏ –¥–æ–º–µ–Ω –∫ IDNA).
    –í –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–µ ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ canonical_email() c –º—è–≥–∫–∏–º —Ñ–æ–ª–±—ç–∫–æ–º.
    """

    try:
        a = (addr or "").strip()
        # –±–∞–∑–æ–≤–∞—è –ø–æ–¥—á–∏—Å—Ç–∫–∞ —Ç–∏–ø–∏—á–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        a = a.strip("()[]{}<>,;")
        return canonical_email(a)
    except Exception as e:
        logger.warning("repair_email fallback for %r: %s", addr, e)
        return (addr or "").strip().lower()


def sanitize_email(addr: str) -> str:
    """
    Legacy wrapper: —Ä–∞–Ω—å—à–µ —É–¥–∞–ª—è–ª–∞ –ø—Ä–æ–±–µ–ª—ã –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ e-mail.
    –¢–µ–ø–µ—Ä—å –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç canonical_email(), —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–µ–∂–Ω–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.
    """

    try:
        a = (addr or "").strip()
        # –ü–æ–¥—á–∏—Å—Ç–∏–º –≤–∏–¥–∏–º—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏ —Å–∫–æ–±–∫–∏, –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –æ—Å—Ç–∞–ª–∏—Å—å
        a = a.strip("()[]{}<>,;\"'`¬´¬ª‚Äû‚Äú‚Äù‚Äö‚Äò‚Äô")
        return canonical_email(a)
    except Exception as e:
        logger.warning("sanitize_email fallback for %r: %s", addr, e)
        return (addr or "").strip().lower()


def get_variants(addr: str):
    """
    Legacy: –≤–µ—Ä–Ω—É—Ç—å –Ω–∞–±–æ—Ä –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∞–¥—Ä–µ—Å–∞.
    –ß—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏ –Ω–µ –ª–æ–º–∞—Ç—å —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É,
    –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –Ω–∞–±–æ—Ä: —Ç–æ–ª—å–∫–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π –∏ –∏—Å—Ö–æ–¥–Ω—ã–π.
    –ï—Å–ª–∏ —Å—Ç–∞—Ä—ã–π –∫–æ–¥ –æ–∂–∏–¥–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ/–∏—Ç–µ—Ä–∏—Ä—É–µ–º–æ–µ ‚Äî —ç—Ç–æ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ.
    """

    try:
        canon = canonical_email(addr)
        base = (addr or "").strip().lower()
        s = {canon}
        if base and base != canon:
            s.add(base)
        return s
    except Exception:
        a = (addr or "").strip().lower()
        return {a} if a else set()


# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —ç–∫—Å–ø–æ—Ä—Ç–æ–≤


_FOOTNOTE_PREFIX_RE = re.compile(r"^(?:[\[(]?\d+[\])]?[\s_.:\-]*)+")


def _strip_leading_footnote(local: str) -> str:
    """Legacy helper: strip leading numeric footnote markers from ``local`` part."""

    if not local:
        return local
    return _FOOTNOTE_PREFIX_RE.sub("", local)


def _normalize_text(text: str) -> str:
    """Legacy wrapper delegating to :mod:`utils.text_normalize`."""

    from utils.text_normalize import normalize_text

    return normalize_text(text)
def _check_legacy_exports():
    required = {
        "dedupe_with_variants",
        "finalize_email",
        "normalize_email",
        "repair_email",
        "get_variants",
        "sanitize_email",
        "canonical_email",
        "drop_leading_char_twins",
        "drop_trailing_char_twins",
    }
    missing = [r for r in required if r not in globals()]
    if missing:
        logger.warning("email_clean: missing legacy exports: %s", missing)


_check_legacy_exports()

# ---------------------------------------------------------------------------
#  –≠–∫—Å–ø–æ—Ä—Ç —á–µ—Ä–µ–∑ __all__ (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç)
# ---------------------------------------------------------------------------
try:
    __all__
except NameError:
    __all__ = []
if isinstance(__all__, (list, tuple, set)):
    if "dedupe_keep_original" not in __all__:
        try:
            __all__ = list(__all__) + ["dedupe_keep_original"]
        except Exception:
            pass

# –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –≤—ã–≤–µ–¥–µ–º –≤ –ª–æ–≥ —Ñ–∞–∫—Ç –Ω–∞–ª–∏—á–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
try:
    logger.info("email_clean: dedupe_keep_original present: %s", "dedupe_keep_original" in globals())
except Exception:
    pass


# ---------------------------------------------------------------------------
# üß© –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º
# ---------------------------------------------------------------------------

def is_valid_email(addr: str) -> bool:
    """–†–∞–Ω—å—à–µ –ø—Ä–æ–≤–µ—Ä—è–ª–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å e-mail; —Ç–µ–ø–µ—Ä—å –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ EMAIL_RE."""
    if not addr:
        return False
    return bool(EMAIL_RE.fullmatch(addr.strip().lower()))


def strict_validate_domain(addr: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–º–µ–Ω–∞ –ø–æ STRICT_DOMAIN_VALIDATE (–∏–∑ .env)."""
    try:
        if not addr or "@" not in addr:
            return False
        dom = addr.split("@", 1)[1]
        if os.getenv("STRICT_DOMAIN_VALIDATE", "1") == "1":
            return bool(re.fullmatch(r"[a-z0-9\-]+(\.[a-z0-9\-]+)+", dom.lower()))
        return True
    except Exception:
        return False


def looks_like_email(text: str) -> bool:
    """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –ø–æ—Ö–æ–∂–µ –ª–∏ –Ω–∞ e-mail (—Ä–∞–Ω—å—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ)."""
    return bool(EMAIL_RE.search(text or ""))


def safe_parse_email(text: str):
    """–†–∞–Ω—å—à–µ –≤–æ–∑–≤—Ä–∞—â–∞–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∞–¥—Ä–µ—Å –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ."""
    try:
        emails = parse_emails_unified(text)
        return emails[0] if emails else None
    except Exception:
        return None


def split_email(text: str):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç local –∏ domain (—Å—Ç–∞—Ä—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å)."""
    try:
        local, dom = (text or "").split("@", 1)
        return local.strip(), dom.strip()
    except Exception:
        return "", ""


def strip_bad_chars(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –∫–∞–≤—ã—á–∫–∏, –ø—Ä–æ–±–µ–ª—ã, —Å–∫–æ–±–∫–∏ –≤–æ–∫—Ä—É–≥ e-mail."""
    return (text or "").strip("()[]{}<>,;\"'`¬´¬ª‚Äû‚Äú‚Äù‚Äö‚Äò‚Äô ")


def normalize_domain(dom: str) -> str:
    """–ü—Ä–∏–≤–µ—Å—Ç–∏ –¥–æ–º–µ–Ω –∫ IDNA / lowercase."""
    try:
        return _idna_domain(dom)
    except Exception:
        return (dom or "").lower()


def extract_possible_emails(text: str):
    """–†–∞–Ω—å—à–µ –≤–æ–∑–≤—Ä–∞—â–∞–ª–∞ —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ (–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)."""
    try:
        return EMAIL_RE.findall(preclean_for_email_extraction(text))
    except Exception:
        return []


def remove_bad_glyphs(text: str) -> str:
    """–£–¥–∞–ª–∏—Ç—å –Ω–µ–≤–∏–¥–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã, zero-width, soft hyphens."""
    return strip_invisibles(text)


def normalize_confusables(text: str) -> str:
    """–ü—Å–µ–≤–¥–æ–Ω–∏–º –¥–ª—è _normalize_confusables()."""
    return _normalize_confusables(text)


def fix_confusables(text: str) -> str:
    """–ï—â—ë –æ–¥–∏–Ω —Å–∏–Ω–æ–Ω–∏–º —Å—Ç–∞—Ä–æ–π —Ñ—É–Ω–∫—Ü–∏–∏."""
    return _normalize_confusables(text)


def email_variants(addr: str):
    """Alias –¥–ª—è get_variants()."""
    return get_variants(addr)


def clean_local_part(addr: str) -> str:
    """–í–µ—Ä–Ω—É—Ç—å —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—É—é —á–∞—Å—Ç—å (–¥–æ @)."""
    return (addr or "").split("@", 1)[0].strip()


def safe_split_email(addr: str):
    """Alias split_email() –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –º–æ–¥—É–ª–µ–π."""
    return split_email(addr)

